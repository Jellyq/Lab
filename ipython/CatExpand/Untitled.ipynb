{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphlab as gl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: data statistics\n",
    "\n",
    "### * to show details of data we have roughly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total lines: 464788\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "file1 = open(r\"C:\\Users\\Jelly\\Desktop\\AI\\AI_data2.csv\", 'rb')\n",
    "file2 = open(r\"C:\\Users\\Jelly\\Desktop\\AI\\AI_data2.txt\", 'w+')\n",
    "count = 0\n",
    "for line in file1:\n",
    "    count += 1\n",
    "    file2.write(line)\n",
    "        \n",
    "file1.close()\n",
    "file2.close()\n",
    "\n",
    "print \"total lines: %d\" % count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * remember to  change coding of file2 to 'utf-8'\n",
    "### * save as AI_data.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: C:\\Users\\Jelly\\AppData\\Local\\Temp\\graphlab_server_1497857850.log.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to qyr16@mails.tsinghua.edu.cn and will expire on September 05, 2017.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Jelly\\Desktop\\AI\\AI_data.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Jelly\\Desktop\\AI\\AI_data.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.84111 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.84111 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[float,float,str,long,str,str,str,long,long,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Read 296947 lines. Lines per second: 363344</pre>"
      ],
      "text/plain": [
       "Read 296947 lines. Lines per second: 363344"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Jelly\\Desktop\\AI\\AI_data.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Jelly\\Desktop\\AI\\AI_data.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 464787 lines in 1.10107 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 464787 lines in 1.10107 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+------------------+-------------+------------+\n",
      "|     ﻿id     |     ran     |        bm        | sale_ord_id | yn_compele |\n",
      "+-------------+-------------+------------------+-------------+------------+\n",
      "| 0.000187055 | 0.008938662 | 01MAR12:00:00:00 |  182825305  |    完成    |\n",
      "| 0.000187055 | 0.008938662 | 01MAR12:00:00:00 |  185323383  |    完成    |\n",
      "| 0.000187055 | 0.008938662 | 01MAR12:00:00:00 |  185323383  |    完成    |\n",
      "| 0.000187055 | 0.008938662 | 01MAR12:00:00:00 |  195777778  |    完成    |\n",
      "| 0.000187055 | 0.008938662 | 01MAR12:00:00:00 |  195777778  |    完成    |\n",
      "| 0.000187055 | 0.008938662 | 01MAR12:00:00:00 |  195777778  |    完成    |\n",
      "| 0.000187055 | 0.008938662 | 01MAR12:00:00:00 |  195777778  |    完成    |\n",
      "| 0.000187055 | 0.008938662 | 01MAR12:00:00:00 |  195777778  |    完成    |\n",
      "| 0.000187055 | 0.008938662 | 01MAR12:00:00:00 |  195767533  |    完成    |\n",
      "| 0.000187055 | 0.008938662 | 01MAR12:00:00:00 |  195767533  |    完成    |\n",
      "+-------------+-------------+------------------+-------------+------------+\n",
      "+-------------+---------------------------------------------+---------------------+\n",
      "| sale_ord_dt |                  item_name                  | before_prefr_amount |\n",
      "+-------------+---------------------------------------------+---------------------+\n",
      "|  2012/3/21  |      联想（lenovo）IdeaCentre A320 ...      |         5199        |\n",
      "|  2012/3/25  |      三星（SAMSUNG）32G TF（MicroSD/...     |         369         |\n",
      "|  2012/3/25  |      富士（FUJIFILM） FinePix F775 ...      |         2218        |\n",
      "|  2012/4/12  |     Double A A4 80克复印纸  （500张/...     |         139         |\n",
      "|  2012/4/12  |      吉星（Jetion）JET-DBG003  A3/A...      |         899         |\n",
      "|  2012/4/12  |  联想（Lenovo）扬天M7100d 台式电脑（四核... |         4999        |\n",
      "|  2012/4/12  | 联想（Lenovo）商用20.0英寸宽屏显示器（16... |          0          |\n",
      "|  2012/4/12  |  联想（Lenovo）C325 20英寸一体电脑（双核... |         3099        |\n",
      "|  2012/4/12  |    金万年便易记号笔10支装G-900-001黑色...   |          14         |\n",
      "|  2012/4/12  |  渡边GAMBOL 6号螺旋装订笔记本S6807杂色1...  |          49         |\n",
      "+-------------+---------------------------------------------+---------------------+\n",
      "+-----------+--------+------------+----------+-----------+\n",
      "| sale_qtty | yn_pop |    cat1    |   cat2   |    cat3   |\n",
      "+-----------+--------+------------+----------+-----------+\n",
      "|     1     |  自营  | 电脑、办公 | 电脑整机 |   台式机  |\n",
      "|     1     |  自营  |  手机数码  | 数码配件 |   存储卡  |\n",
      "|     1     |  自营  |  手机数码  | 摄影摄像 |  数码相机 |\n",
      "|     1     |  自营  | 电脑、办公 | 办公文仪 |    纸类   |\n",
      "|     1     |  自营  | 电脑、办公 | 办公打印 |   扫描仪  |\n",
      "|     1     |  自营  | 电脑、办公 | 电脑整机 |   台式机  |\n",
      "|     1     |  自营  | 电脑、办公 | 电脑整机 |   台式机  |\n",
      "|     1     |  自营  | 电脑、办公 | 电脑整机 |   台式机  |\n",
      "|     1     |  自营  | 电脑、办公 | 办公文仪 |    笔类   |\n",
      "|     1     |  自营  | 电脑、办公 | 办公文仪 | 本册/便签 |\n",
      "+-----------+--------+------------+----------+-----------+\n",
      "[464787 rows x 13 columns]\n",
      "Note: Only the head of the SFrame is printed.\n",
      "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n"
     ]
    }
   ],
   "source": [
    "data = gl.SFrame.read_csv(r\"C:\\Users\\Jelly\\Desktop\\AI\\AI_data.txt\", header = True)\n",
    "print data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\xef\\xbb\\xbfid', 'ran', 'bm', 'sale_ord_id', 'yn_compele', 'sale_ord_dt', 'item_name', 'before_prefr_amount', 'sale_qtty', 'yn_pop', 'cat1', 'cat2', 'cat3']\n"
     ]
    }
   ],
   "source": [
    "print data.column_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total user number: 10000\n",
      "total cat1 number: 48\n",
      "total cat2 number: 554\n",
      "total cat3 number: 2240\n"
     ]
    }
   ],
   "source": [
    "user_num = len(data['\\xef\\xbb\\xbfid'].unique())\n",
    "print \"total user number: %d\" % user_num\n",
    "cat1_num = len(data['cat1'].unique())\n",
    "print \"total cat1 number: %d\" % cat1_num\n",
    "cat2_num = len(data['cat2'].unique())\n",
    "print \"total cat2 number: %d\" % cat2_num\n",
    "cat3_num = len(data['cat3'].unique())\n",
    "print \"total cat3 number: %d\" % cat3_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JD self-run percentage: 0.805997\n",
      "total buying records: 464787\n"
     ]
    }
   ],
   "source": [
    "percentage = 1.0 * len(data[data['yn_pop'] == u'自营'])/ len(data)\n",
    "total = count - 1\n",
    "print \"JD self-run percentage: %f\" % percentage\n",
    "print \"total buying records: %d\" % total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canvas is updated and available in a tab in the default browser.\n"
     ]
    }
   ],
   "source": [
    "data2 = data.groupby(key_columns='\\xef\\xbb\\xbfid', operations={r'cat1_count': gl.aggregate.COUNT_DISTINCT('cat1'),\n",
    "                                                              r'cat2_count': gl.aggregate.COUNT_DISTINCT('cat2'),\n",
    "                                                              r'cat3_count': gl.aggregate.COUNT_DISTINCT('cat3'),\n",
    "                                                              r'buying_count': gl.aggregate.COUNT('bm')})\n",
    "data2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: data selection\n",
    "\n",
    "### * the aim of this part is to form sentence of each user according to their buying time\n",
    "### * the words of a sentence are goods' categaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jelly\\Anaconda2\\envs\\gl-env\\lib\\site-packages\\ipykernel\\__main__.py:24: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sentences number: 464787\n",
      "---------------Sentences Demo--------------------\n",
      "[u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u624b\\u673a\\u6570\\u7801', u'\\u624b\\u673a\\u6570\\u7801', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u56fe\\u4e66', u'\\u5bb6\\u7528\\u7535\\u5668', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u56fe\\u4e66', u'\\u5bb6\\u7528\\u7535\\u5668', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u5bb6\\u7528\\u7535\\u5668', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u5bb6\\u7528\\u7535\\u5668', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u624b\\u673a', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u793c\\u54c1\\u7bb1\\u5305']\n",
      "['\\xe5\\xae\\xb6\\xe7\\x94\\xa8\\xe7\\x94\\xb5\\xe5\\x99\\xa8', u'\\u53a8\\u5177']\n",
      "['\\xe6\\x89\\x8b\\xe6\\x9c\\xba\\xe6\\x95\\xb0\\xe7\\xa0\\x81', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u5bb6\\u5c45\\u5bb6\\u88c5', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u793c\\u54c1\\u7bb1\\u5305', u'\\u56fe\\u4e66', u'\\u56fe\\u4e66', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u5bb6\\u7528\\u7535\\u5668', u'\\u5bb6\\u7528\\u7535\\u5668', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u56fe\\u4e66', u'\\u56fe\\u4e66', u'\\u56fe\\u4e66', u'\\u56fe\\u4e66', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u56fe\\u4e66', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u8fd0\\u52a8\\u5065\\u5eb7', u'\\u5bb6\\u5c45\\u5bb6\\u88c5', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u5bb6\\u5c45\\u5bb6\\u88c5', u'\\u53a8\\u5177', u'\\u5ba0\\u7269\\u751f\\u6d3b', u'\\u793c\\u54c1\\u7bb1\\u5305', u'\\u4e2a\\u62a4\\u5316\\u5986', u'\\u98df\\u54c1\\u996e\\u6599\\u3001', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u7535\\u8111\\u3001\\u529e\\u516c', u'\\u6570\\u7801', u'\\u5ba0\\u7269\\u751f\\u6d3b', u'\\u5ba0\\u7269\\u751f\\u6d3b', u'\\u8fd0\\u52a8\\u5065\\u5eb7', u'\\u5bb6\\u5c45\\u5bb6\\u88c5', u'\\u5ba0\\u7269\\u751f\\u6d3b', u'\\u5ba0\\u7269\\u751f\\u6d3b', u'\\u98df\\u54c1\\u996e\\u6599\\u3001', u'\\u98df\\u54c1\\u996e\\u6599\\u3001', u'\\u5bb6\\u5177', u'\\u5ba0\\u7269\\u751f\\u6d3b', u'\\u5ba0\\u7269\\u751f\\u6d3b', u'\\u56fe\\u4e66', u'\\u56fe\\u4e66']\n",
      "['\\xe6\\xaf\\x8d\\xe5\\xa9\\xb4']\n",
      "['\\xe9\\xa3\\x9f\\xe5\\x93\\x81\\xe9\\xa5\\xae\\xe6\\x96\\x99\\xe3\\x80\\x81', u'\\u670d\\u9970\\u5185\\u8863', u'\\u670d\\u9970\\u5185\\u8863']\n"
     ]
    }
   ],
   "source": [
    "# read data:\n",
    "file1 = r\"C:\\Users\\Jelly\\Desktop\\AI\\AI_data.txt\"\n",
    "\n",
    "import csv\n",
    "count = 0\n",
    "L = [] # list of lists, storing all the sentences, each is a list\n",
    "vocab = set()\n",
    "with open(file1, 'rb') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    l = [] # list, storing words of a sentence\n",
    "    for row in reader:\n",
    "        if count == 0:\n",
    "            count +=1\n",
    "            user_old = row['\\xef\\xbb\\xbfid']\n",
    "            user_new = row['\\xef\\xbb\\xbfid']\n",
    "            cat = row['cat1'] # using Cat2\n",
    "            l.append(cat.decode('utf-8'))\n",
    "            vocab.add(cat.decode('utf-8'))\n",
    "        else:\n",
    "            count += 1\n",
    "            user_new = row['\\xef\\xbb\\xbfid']\n",
    "            cat = row['cat1']\n",
    "            if user_new == user_old:\n",
    "                if not cat in l:\n",
    "                    l.append(cat.decode('utf-8'))\n",
    "                    vocab.add(cat.decode('utf-8'))\n",
    "            else:\n",
    "                L.append(l)\n",
    "                l = []\n",
    "                l.append(cat)\n",
    "                user_old = user_new\n",
    "    csvfile.close()\n",
    "print \"total sentences number: %d\" % count\n",
    "print \"---------------Sentences Demo--------------------\"\n",
    "count  = 0\n",
    "for i in L:\n",
    "    print i\n",
    "    count += 1\n",
    "    if count > 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save vocab and sentences get above\n",
    "import pickle\n",
    "\n",
    "vocab_file = pickle.dump(vocab, open(\"vocab1.pickle\", 'wb'))\n",
    "sentence_file = pickle.dump(L, open(\"text1.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: word embedding\n",
    "\n",
    "### * the aim is to transform words in vocab to 2 dimentional vectors\n",
    "### * code is on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "l = [[1, 2], [3, 4, 5]]\n",
    "ll = [x for j in l for x in j]\n",
    "print (ll)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
